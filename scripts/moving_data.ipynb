{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing\n",
    "## Action Plan\n",
    "1. Create Validation and Sample sets\n",
    "2. Rearrange image files into their respective directories "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/nathan/git/planktonDataScienceBowl/scripts'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create references to important directories we will use over and over\n",
    "import os, sys\n",
    "current_dir = os.getcwd()\n",
    "SCRIPTS_HOME_DIR = current_dir\n",
    "DATA_HOME_DIR = current_dir+'/data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using tensorflow with theano image ordering to match utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import numpy as np\n",
    "import _pickle as pickle\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from PIL import ImageOps\n",
    "from tqdm import tqdm\n",
    "import bcolz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX 1070 (CNMeM is enabled with initial size: 85.0% of memory, cuDNN 5105)\n",
      "/home/nathan/anaconda3/envs/deepLearning/lib/python3.5/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "#import modules\n",
    "from utils import *\n",
    "from vgg16 import Vgg16\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create validation set and sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mdata\u001b[0m/              plankton_model.ipynb        \u001b[01;34m__pycache__\u001b[0m/  \u001b[01;32mvgg16bn.py\u001b[0m*\r\n",
      "moving_data.ipynb  plankton_model_vgg16.ipynb  \u001b[01;32mutils.py\u001b[0m*     \u001b[01;32mvgg16.py\u001b[0m*\r\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/nathan/git/planktonDataScienceBowl/scripts/data\n"
     ]
    }
   ],
   "source": [
    "#Create directories\n",
    "%cd $DATA_HOME_DIR\n",
    "%mkdir valid\n",
    "%mkdir results\n",
    "%mkdir -p sample/train\n",
    "%mkdir -p sample/test\n",
    "%mkdir -p sample/valid\n",
    "%mkdir -p sample/results\n",
    "%mkdir -p test/unknown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/nathan/git/planktonDataScienceBowl/scripts/data/train\n"
     ]
    }
   ],
   "source": [
    "%cd $DATA_HOME_DIR/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "folders = ([name for name in os.listdir(\".\") if os.path.isdir(name)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for folder in folders:\n",
    "    os.chdir(DATA_HOME_DIR + '/train/' + folder)\n",
    "    g = glob('*.jpg')\n",
    "    shuf = np.random.permutation(g)\n",
    "    try:\n",
    "        os.mkdir(DATA_HOME_DIR+'/valid/'+ folder)\n",
    "    except:\n",
    "        pass\n",
    "    for i in range(round(len(shuf)/10 + 1)): os.rename(shuf[i], DATA_HOME_DIR+'/valid/'+ folder + '/' + shuf[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# need to copy files - use copyfile\n",
    "from shutil import copyfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample\n",
    "Make sample training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# g = glob('*.jpg')\n",
    "# shuf = np.random.permutation(g)\n",
    "# for i in range(200): copyfile(shuf[i], DATA_HOME_DIR+'/sample/train/' + shuf[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next make sample validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %cd $DATA_HOME_DIR/valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# g = glob('*.jpg')\n",
    "# shuf = np.random.permutation(g)\n",
    "# for i in range(50): copyfile(shuf[i], DATA_HOME_DIR+'/sample/valid/' + shuf[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rearrange image files into their respective directories\n",
    "\n",
    "Dogs and cats need to be in their respective folders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %cd $DATA_HOME_DIR/valid\n",
    "# %mkdir cats\n",
    "# %mkdir dogs\n",
    "# %mv cat.*.jpg cats/\n",
    "# %mv dog.*.jpg dogs/\n",
    "\n",
    "# %cd $DATA_HOME_DIR/train\n",
    "# %mkdir cats\n",
    "# %mkdir dogs\n",
    "# %mv cat.*.jpg cats/\n",
    "# %mv dog.*.jpg dogs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %cd $DATA_HOME_DIR/sample/train\n",
    "# %mkdir cats\n",
    "# %mkdir dogs\n",
    "# %mv cat.*.jpg cats/\n",
    "# %mv dog.*.jpg dogs/\n",
    "\n",
    "# %cd $DATA_HOME_DIR/sample/valid\n",
    "# %mkdir cats\n",
    "# %mkdir dogs\n",
    "# %mv cat.*.jpg cats/\n",
    "# %mv dog.*.jpg dogs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/nathan/git/planktonDataScienceBowl/scripts/data/test\n"
     ]
    }
   ],
   "source": [
    "# Create single 'unknown' class for test set\n",
    "%cd $DATA_HOME_DIR/test\n",
    "%mv *.jpg unknown/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Info on image size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def resize_save_image(image_path):\n",
    "    # open image and get array\n",
    "    image_array = np.asarray(Image.open(image_path))\n",
    "    \n",
    "    # save image size (not necessary but easier to think about)\n",
    "    image_shape = image_array.shape\n",
    "    \n",
    "    # determine padding\n",
    "    if image_shape[0] > image_shape[1]:\n",
    "        padH = int((image_shape[0] - image_shape[1]) / 2)\n",
    "        padV = 0\n",
    "\n",
    "    if image_shape[1] > image_shape[0]:\n",
    "        padH = 0\n",
    "        padV = int((image_shape[1] - image_shape[0]) / 2)\n",
    "\n",
    "    if image_shape[1] == image_shape[0]:\n",
    "        padH = 0\n",
    "        padV = 0\n",
    "\n",
    "    # apply padding\n",
    "    padded_array = np.pad(image_array, ((padV,padV),(padH,padH)), \n",
    "                          mode='constant', constant_values=255)\n",
    "    \n",
    "    # convert back to image\n",
    "    img = Image.fromarray(padded_array, 'L')\n",
    "    \n",
    "    # resize image to square (max 1 pixel resize)\n",
    "    square = (np.max(image_array.shape))\n",
    "    img = img.resize((square,square))\n",
    "    \n",
    "    # invert colors\n",
    "#     img = ImageOps.invert(img)\n",
    "    \n",
    "    # save image\n",
    "    img.save(image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/nathan/git/planktonDataScienceBowl/scripts/data/train\n"
     ]
    }
   ],
   "source": [
    "%cd $DATA_HOME_DIR/train\n",
    "folders = ([name for name in os.listdir(\".\") if os.path.isdir(name)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for folder in folders:\n",
    "    os.chdir(DATA_HOME_DIR + '/train/' + folder)\n",
    "    g = glob('*.jpg')\n",
    "    for image_path in g:\n",
    "        resize_save_image(image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/nathan/git/planktonDataScienceBowl/scripts/data/valid\n"
     ]
    }
   ],
   "source": [
    "%cd $DATA_HOME_DIR/valid\n",
    "folders = ([name for name in os.listdir(\".\") if os.path.isdir(name)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for folder in folders:\n",
    "    os.chdir(DATA_HOME_DIR + '/valid/' + folder)\n",
    "    g = glob('*.jpg')\n",
    "    for image_path in g:\n",
    "        resize_save_image(image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/nathan/git/planktonDataScienceBowl/scripts/data/test\n"
     ]
    }
   ],
   "source": [
    "%cd $DATA_HOME_DIR/test\n",
    "folders = ([name for name in os.listdir(\".\") if os.path.isdir(name)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for folder in folders:\n",
    "    os.chdir(DATA_HOME_DIR + '/test/' + folder)\n",
    "    g = glob('*.jpg')\n",
    "    for image_path in g:\n",
    "        resize_save_image(image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/nathan/git/planktonDataScienceBowl/scripts/data/train\n"
     ]
    }
   ],
   "source": [
    "%cd $DATA_HOME_DIR/train\n",
    "folders = ([name for name in os.listdir(\".\") if os.path.isdir(name)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/121 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed to concatenate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 121/121 [16:58<00:00,  9.57s/it]\n"
     ]
    }
   ],
   "source": [
    "X_train = None\n",
    "for folder in tqdm(folders):\n",
    "    os.chdir(DATA_HOME_DIR + '/train/' + folder)\n",
    "    g = glob('*.jpg')\n",
    "    for image_path in g:\n",
    "        image_array = np.asarray(Image.open(image_path).resize((128,128)))\n",
    "        try:\n",
    "            X_train = np.concatenate((X_train, image_array), axis=0)\n",
    "        except:\n",
    "            print (\"failed to concatenate\")\n",
    "            X_train = image_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/nathan/git/planktonDataScienceBowl/scripts/data/valid\n"
     ]
    }
   ],
   "source": [
    "%cd $DATA_HOME_DIR/valid\n",
    "folders = ([name for name in os.listdir(\".\") if os.path.isdir(name)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(33487, 128, 128)[:27184].reshape(3479552, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/121 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|          | 1/121 [00:01<02:27,  1.23s/it]\u001b[A\n",
      "100%|██████████| 121/121 [03:49<00:00,  1.17s/it]\n"
     ]
    }
   ],
   "source": [
    "for folder in tqdm(folders):\n",
    "    os.chdir(DATA_HOME_DIR + '/valid/' + folder)\n",
    "    g = glob('*.jpg')\n",
    "    for image_path in g:\n",
    "        image_array = np.asarray(Image.open(image_path).resize((128,128)))\n",
    "        X_train = np.concatenate((X_train, image_array), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imgs = int(X_train.shape[0]/128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train2 = X_train.reshape(imgs, 1, 128, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.868742"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train2.mean().astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38.339569"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train2.std().astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train3 = X_train2/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.046544086"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train3.mean().astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15035126"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train3.std().astype(np.float32)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:deepLearning]",
   "language": "python",
   "name": "conda-env-deepLearning-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
