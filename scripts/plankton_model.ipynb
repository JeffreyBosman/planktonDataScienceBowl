{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# National Data Science Bowl - Plankton\n",
    "\n",
    "## Action Plan\n",
    "\n",
    "* Make overfitting model\n",
    "* Data augmentation\n",
    "* Batch normalization\n",
    "* Dropout\n",
    "* Ensembling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Imports and Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Create references to important directories we will use over and over\n",
    "import os, sys\n",
    "current_dir = os.getcwd()\n",
    "SCRIPTS_HOME_DIR = current_dir\n",
    "DATA_HOME_DIR = current_dir+'/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: GeForce GTX 1070 (CNMeM is enabled with initial size: 90.0% of memory, cuDNN 5105)\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "#import modules\n",
    "from utils import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/nathan/git/planktonDataScienceBowl/scripts/data\n"
     ]
    }
   ],
   "source": [
    "%cd $DATA_HOME_DIR\n",
    "\n",
    "#Set path to sample/ path if desired\n",
    "path = DATA_HOME_DIR #'/sample/'\n",
    "test_path = DATA_HOME_DIR + '/test/' #We use all the test data\n",
    "results_path=DATA_HOME_DIR + '/results/'\n",
    "train_path=path + '/train/'\n",
    "valid_path=path + '/valid/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## VGG Like Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "img_rows, img_cols = 128, 128\n",
    "in_shape = (img_rows, img_cols)\n",
    "batch_size = 64\n",
    "nb_classes = 121"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "gen = image.ImageDataGenerator(rescale=1. / 255)\n",
    "# gen = image.ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 27184 images belonging to 121 classes.\n",
      "Found 3152 images belonging to 121 classes.\n"
     ]
    }
   ],
   "source": [
    "train_batches = get_batches(train_path, batch_size=batch_size, \n",
    "                            target_size=in_shape, color_mode=\"grayscale\", \n",
    "                            gen=gen)\n",
    "val_batches   = get_batches(valid_path, batch_size=batch_size, \n",
    "                            target_size=in_shape, color_mode=\"grayscale\", \n",
    "                            gen=gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = Sequential([\n",
    "        Convolution2D(64,3,3, border_mode='same', activation='relu', input_shape=(1, img_rows, img_cols)),\n",
    "        Convolution2D(64,3,3, border_mode='same', activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        Convolution2D(128,3,3, border_mode='same', activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        Convolution2D(256,3,3, border_mode='same', activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        Flatten(),\n",
    "        Dense(2048, activation='relu'),\n",
    "        Dense(2048, activation='relu'),\n",
    "        Dense(2048, activation='relu'),\n",
    "        Dense(nb_classes, activation='softmax')\n",
    "        ])\n",
    "    model.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_1 (Convolution2D)  (None, 64, 128, 128)  640         convolution2d_input_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 64, 128, 128)  36928       convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_1 (MaxPooling2D)    (None, 64, 64, 64)    0           convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)  (None, 128, 64, 64)   73856       maxpooling2d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_2 (MaxPooling2D)    (None, 128, 32, 32)   0           convolution2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_4 (Convolution2D)  (None, 256, 32, 32)   295168      maxpooling2d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_3 (MaxPooling2D)    (None, 256, 16, 16)   0           convolution2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 65536)         0           maxpooling2d_3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 2048)          134219776   flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 2048)          4196352     dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 2048)          4196352     dense_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 121)           247929      dense_3[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 143,267,001\n",
      "Trainable params: 143,267,001\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      " 3776/27184 [===>..........................] - ETA: 95s - loss: 4.0138 - acc: 0.1205"
     ]
    }
   ],
   "source": [
    "model.fit_generator(train_batches, samples_per_epoch=train_batches.nb_sample,\n",
    "                    nb_epoch=5,\n",
    "                    validation_data=val_batches,\n",
    "                    nb_val_samples=val_batches.nb_sample,\n",
    "                    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr=0.1\n",
    "model.fit_generator(train_batches, samples_per_epoch=train_batches.nb_sample,\n",
    "                    nb_epoch=1,\n",
    "                    validation_data=val_batches, nb_val_samples=val_batches.nb_sample,\n",
    "                    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr=0.01\n",
    "model.fit_generator(train_batches, samples_per_epoch=train_batches.nb_sample,\n",
    "                    nb_epoch=4,\n",
    "                    validation_data=val_batches, nb_val_samples=val_batches.nb_sample,\n",
    "                    verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "img_rows, img_cols = 128, 128\n",
    "in_shape = (img_rows, img_cols)\n",
    "batch_size = 64\n",
    "nb_classes = 121\n",
    "mean_px = 0.046544086\n",
    "std_px = 0.15035126"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "batch_gen = image.ImageDataGenerator(\n",
    "                rotation_range=360,\n",
    "                width_shift_range=0.03,\n",
    "                height_shift_range=0.03,\n",
    "                shear_range=0.10,\n",
    "                zoom_range=0.10,\n",
    "                rescale=1. / 255,\n",
    "                horizontal_flip = True,\n",
    "                vertical_flip = True)\n",
    "\n",
    "valid_gen = image.ImageDataGenerator(\n",
    "#                                      featurewise_center=True,\n",
    "#                                      featurewise_std_normalization=True,\n",
    "                                     rescale=1. / 255\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 27184 images belonging to 121 classes.\n",
      "Found 3152 images belonging to 121 classes.\n"
     ]
    }
   ],
   "source": [
    "train_batches = get_batches(train_path, batch_size=batch_size, \n",
    "                            target_size=in_shape, color_mode=\"grayscale\", \n",
    "                            gen=batch_gen)\n",
    "val_batches   = get_batches(valid_path, batch_size=batch_size, \n",
    "                            target_size=in_shape, color_mode=\"grayscale\", \n",
    "                            gen=valid_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def norm_input(x): \n",
    "    return x\n",
    "    return (x-mean_px)/(std_px)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = Sequential([\n",
    "#         Convolution2D(64,3,3, border_mode='same', activation='relu', input_shape=(1, img_rows, img_cols)),\n",
    "        Lambda(norm_input, input_shape=(1, img_rows, img_cols), output_shape=(1, img_rows, img_cols)),\n",
    "        Convolution2D(64,3,3, border_mode='same', activation='relu'),\n",
    "        Convolution2D(64,3,3, border_mode='same', activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        Convolution2D(128,3,3, border_mode='same', activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        Convolution2D(256,3,3, border_mode='same', activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        Flatten(),\n",
    "        Dense(2048, activation='relu'),\n",
    "        Dense(2048, activation='relu'),\n",
    "        Dense(2048, activation='relu'),\n",
    "        Dense(nb_classes, activation='softmax')\n",
    "        ])\n",
    "    model.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nathan/anaconda3/envs/deepLearning/lib/python3.5/site-packages/keras/engine/topology.py:1811: UserWarning: Model inputs must come from a Keras Input layer, they cannot be the output of a previous non-Input layer. Here, a tensor specified as input to \"sequential_2_model\" was not an Input tensor, it was generated by layer lambda_2.\n",
      "Note that input tensors are instantiated via `tensor = Input(shape)`.\n",
      "The tensor that caused the issue was: lambda_input_2\n",
      "  str(x.name))\n"
     ]
    }
   ],
   "source": [
    "model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lambda_2 (Lambda)                (None, 1, 128, 128)   0           lambda_input_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_5 (Convolution2D)  (None, 64, 128, 128)  640         lambda_2[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_6 (Convolution2D)  (None, 64, 128, 128)  36928       convolution2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_4 (MaxPooling2D)    (None, 64, 64, 64)    0           convolution2d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_7 (Convolution2D)  (None, 128, 64, 64)   73856       maxpooling2d_4[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_5 (MaxPooling2D)    (None, 128, 32, 32)   0           convolution2d_7[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_8 (Convolution2D)  (None, 256, 32, 32)   295168      maxpooling2d_5[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_6 (MaxPooling2D)    (None, 256, 16, 16)   0           convolution2d_8[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)              (None, 65536)         0           maxpooling2d_6[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_5 (Dense)                  (None, 2048)          134219776   flatten_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_6 (Dense)                  (None, 2048)          4196352     dense_5[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_7 (Dense)                  (None, 2048)          4196352     dense_6[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_8 (Dense)                  (None, 121)           247929      dense_7[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 143,267,001\n",
      "Trainable params: 143,267,001\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "27184/27184 [==============================] - 115s - loss: 2.7705 - acc: 0.2926 - val_loss: 2.1929 - val_acc: 0.3871\n",
      "Epoch 2/25\n",
      "27184/27184 [==============================] - 114s - loss: 1.9655 - acc: 0.4385 - val_loss: 1.7786 - val_acc: 0.4759\n",
      "Epoch 3/25\n",
      " 6912/27184 [======>.......................] - ETA: 84s - loss: 1.7519 - acc: 0.4848"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(train_batches, samples_per_epoch=train_batches.nb_sample,\n",
    "                    validation_data=val_batches, nb_val_samples=val_batches.nb_sample,\n",
    "                    nb_epoch=25, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.save_weights('last_attempt_augmentation.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Visualize Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7fcf099f2e10>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVwAAAFcCAYAAACEFgYsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nELgAYMj/A/VJL5Bk/DO0AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fcf099f2e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame(history.history)\n",
    "df['epoch_number'] = range(len(df))\n",
    "sns.lmplot(x=\"epoch_number\", y=\"val_acc\", data=df, fit_reg=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Data Augmentation + Batch Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "img_rows, img_cols = 128, 128\n",
    "in_shape = (img_rows, img_cols)\n",
    "batch_size = 64\n",
    "nb_classes = 121\n",
    "mean_px = 0.046544086\n",
    "std_px = 0.15035126"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "batch_gen = image.ImageDataGenerator(\n",
    "                rotation_range=360,\n",
    "                width_shift_range=0.03,\n",
    "                height_shift_range=0.03,\n",
    "                shear_range=0.10,\n",
    "                zoom_range=0.10,\n",
    "                rescale=1. / 255,\n",
    "                horizontal_flip = True,\n",
    "                vertical_flip = True)\n",
    "\n",
    "valid_gen = image.ImageDataGenerator(\n",
    "                                     rescale=1. / 255\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 27184 images belonging to 121 classes.\n",
      "Found 3152 images belonging to 121 classes.\n"
     ]
    }
   ],
   "source": [
    "train_batches = get_batches(train_path, batch_size=batch_size, \n",
    "                            target_size=in_shape, color_mode=\"grayscale\", \n",
    "                            gen=batch_gen)\n",
    "val_batches   = get_batches(valid_path, batch_size=batch_size, \n",
    "                            target_size=in_shape, color_mode=\"grayscale\", \n",
    "                            gen=valid_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def norm_input(x): return (x-mean_px)/(std_px)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = Sequential([\n",
    "        Lambda(norm_input, input_shape=(1, img_rows, img_cols), output_shape=(1, img_rows, img_cols)),\n",
    "        Convolution2D(64,3,3, border_mode='same', activation='relu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        Convolution2D(64,3,3, border_mode='same', activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        BatchNormalization(axis=1),\n",
    "        Convolution2D(128,3,3, border_mode='same', activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        BatchNormalization(axis=1),\n",
    "        Convolution2D(256,3,3, border_mode='same', activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        Flatten(),\n",
    "        BatchNormalization(),\n",
    "        Dense(2048, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dense(2048, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dense(2048, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dense(nb_classes, activation='softmax')\n",
    "        ])\n",
    "    model.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lambda_1 (Lambda)                (None, 1, 128, 128)   0           lambda_input_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_1 (Convolution2D)  (None, 64, 128, 128)  640         lambda_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_1 (BatchNorma (None, 64, 128, 128)  256         convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 64, 128, 128)  36928       batchnormalization_1[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_1 (MaxPooling2D)    (None, 64, 64, 64)    0           convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_2 (BatchNorma (None, 64, 64, 64)    256         maxpooling2d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)  (None, 128, 64, 64)   73856       batchnormalization_2[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_2 (MaxPooling2D)    (None, 128, 32, 32)   0           convolution2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_3 (BatchNorma (None, 128, 32, 32)   512         maxpooling2d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_4 (Convolution2D)  (None, 256, 32, 32)   295168      batchnormalization_3[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_3 (MaxPooling2D)    (None, 256, 16, 16)   0           convolution2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 65536)         0           maxpooling2d_3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_4 (BatchNorma (None, 65536)         262144      flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 2048)          134219776   batchnormalization_4[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_5 (BatchNorma (None, 2048)          8192        dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 2048)          4196352     batchnormalization_5[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_6 (BatchNorma (None, 2048)          8192        dense_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 2048)          4196352     batchnormalization_6[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_7 (BatchNorma (None, 2048)          8192        dense_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 121)           247929      batchnormalization_7[0][0]       \n",
      "====================================================================================================\n",
      "Total params: 143,554,745\n",
      "Trainable params: 143,410,873\n",
      "Non-trainable params: 143,872\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def update_history(old, new):\n",
    "    for key, value in new.history.items():\n",
    "        old.history[key] = (old.history[key] + value)\n",
    "    return old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "27184/27184 [==============================] - 132s - loss: 3.0283 - acc: 0.3131 - val_loss: 8.0631 - val_acc: 0.0660\n",
      "Epoch 2/30\n",
      "27184/27184 [==============================] - 144s - loss: 2.3078 - acc: 0.4186 - val_loss: 2.6403 - val_acc: 0.3604\n",
      "Epoch 3/30\n",
      "27184/27184 [==============================] - 135s - loss: 2.1343 - acc: 0.4505 - val_loss: 3.2266 - val_acc: 0.2897\n",
      "Epoch 4/30\n",
      "27184/27184 [==============================] - 144s - loss: 1.9885 - acc: 0.4663 - val_loss: 2.7592 - val_acc: 0.3296\n",
      "Epoch 5/30\n",
      "27184/27184 [==============================] - 143s - loss: 1.8535 - acc: 0.4946 - val_loss: 1.7695 - val_acc: 0.5016\n",
      "Epoch 6/30\n",
      "27184/27184 [==============================] - 134s - loss: 1.8714 - acc: 0.4982 - val_loss: 2.2544 - val_acc: 0.4277\n",
      "Epoch 7/30\n",
      "27184/27184 [==============================] - 134s - loss: 1.7590 - acc: 0.5247 - val_loss: 7.0555 - val_acc: 0.1307\n",
      "Epoch 8/30\n",
      "27184/27184 [==============================] - 136s - loss: 1.6618 - acc: 0.5376 - val_loss: 1.6367 - val_acc: 0.5251\n",
      "Epoch 9/30\n",
      "27184/27184 [==============================] - 134s - loss: 1.5032 - acc: 0.5566 - val_loss: 2.1080 - val_acc: 0.4952\n",
      "Epoch 10/30\n",
      "27184/27184 [==============================] - 133s - loss: 1.4133 - acc: 0.5750 - val_loss: 1.8195 - val_acc: 0.5171\n",
      "Epoch 11/30\n",
      "27184/27184 [==============================] - 133s - loss: 1.3503 - acc: 0.5873 - val_loss: 1.5002 - val_acc: 0.5654\n",
      "Epoch 12/30\n",
      "27184/27184 [==============================] - 133s - loss: 1.2887 - acc: 0.6017 - val_loss: 1.4664 - val_acc: 0.5822\n",
      "Epoch 13/30\n",
      "27184/27184 [==============================] - 133s - loss: 1.2650 - acc: 0.6058 - val_loss: 1.5961 - val_acc: 0.5574\n",
      "Epoch 14/30\n",
      "27184/27184 [==============================] - 140s - loss: 1.2246 - acc: 0.6152 - val_loss: 1.9624 - val_acc: 0.4927\n",
      "Epoch 15/30\n",
      "27184/27184 [==============================] - 149s - loss: 1.1835 - acc: 0.6259 - val_loss: 2.5967 - val_acc: 0.3753\n",
      "Epoch 16/30\n",
      "27184/27184 [==============================] - 149s - loss: 1.1525 - acc: 0.6375 - val_loss: 1.6221 - val_acc: 0.5546\n",
      "Epoch 17/30\n",
      "27184/27184 [==============================] - 149s - loss: 1.1284 - acc: 0.6428 - val_loss: 1.7973 - val_acc: 0.5044\n",
      "Epoch 18/30\n",
      "27184/27184 [==============================] - 154s - loss: 1.0974 - acc: 0.6475 - val_loss: 2.0837 - val_acc: 0.4854\n",
      "Epoch 19/30\n",
      "27184/27184 [==============================] - 153s - loss: 1.0895 - acc: 0.6502 - val_loss: 1.3584 - val_acc: 0.6183\n",
      "Epoch 20/30\n",
      "27184/27184 [==============================] - 143s - loss: 1.0564 - acc: 0.6602 - val_loss: 1.5632 - val_acc: 0.5771\n",
      "Epoch 21/30\n",
      "27184/27184 [==============================] - 134s - loss: 1.0358 - acc: 0.6641 - val_loss: 2.0841 - val_acc: 0.5324\n",
      "Epoch 22/30\n",
      "27184/27184 [==============================] - 132s - loss: 1.0112 - acc: 0.6735 - val_loss: 3.9474 - val_acc: 0.3131\n",
      "Epoch 23/30\n",
      "27184/27184 [==============================] - 132s - loss: 0.9858 - acc: 0.6761 - val_loss: 1.4636 - val_acc: 0.6095\n",
      "Epoch 24/30\n",
      "27184/27184 [==============================] - 132s - loss: 0.9660 - acc: 0.6861 - val_loss: 1.6590 - val_acc: 0.5638\n",
      "Epoch 25/30\n",
      "27184/27184 [==============================] - 132s - loss: 0.9394 - acc: 0.6894 - val_loss: 1.2847 - val_acc: 0.6348\n",
      "Epoch 26/30\n",
      "27184/27184 [==============================] - 132s - loss: 0.9232 - acc: 0.6931 - val_loss: 1.2970 - val_acc: 0.6298\n",
      "Epoch 27/30\n",
      "27184/27184 [==============================] - 132s - loss: 0.9096 - acc: 0.6956 - val_loss: 2.4494 - val_acc: 0.4905\n",
      "Epoch 28/30\n",
      "27184/27184 [==============================] - 132s - loss: 0.8793 - acc: 0.7016 - val_loss: 1.9375 - val_acc: 0.4962\n",
      "Epoch 29/30\n",
      "27184/27184 [==============================] - 132s - loss: 0.8587 - acc: 0.7107 - val_loss: 3.4970 - val_acc: 0.4556\n",
      "Epoch 30/30\n",
      "27184/27184 [==============================] - 132s - loss: 0.8532 - acc: 0.7130 - val_loss: 1.3740 - val_acc: 0.6158\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(train_batches, samples_per_epoch=train_batches.nb_sample,\n",
    "                    validation_data=val_batches, nb_val_samples=val_batches.nb_sample,\n",
    "                    nb_epoch=30, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "27184/27184 [==============================] - 185s - loss: 0.8349 - acc: 0.7219 - val_loss: 3.2147 - val_acc: 0.4188\n",
      "Epoch 2/5\n",
      "27184/27184 [==============================] - 185s - loss: 0.8113 - acc: 0.7238 - val_loss: 2.0126 - val_acc: 0.5266\n",
      "Epoch 3/5\n",
      "27184/27184 [==============================] - 185s - loss: 0.7950 - acc: 0.7298 - val_loss: 1.8864 - val_acc: 0.5698\n",
      "Epoch 4/5\n",
      "27184/27184 [==============================] - 185s - loss: 0.7836 - acc: 0.7316 - val_loss: 5.8026 - val_acc: 0.3106\n",
      "Epoch 5/5\n",
      "27184/27184 [==============================] - 185s - loss: 0.7755 - acc: 0.7332 - val_loss: 1.4031 - val_acc: 0.6459\n"
     ]
    }
   ],
   "source": [
    "model.optimizer.lr=0.00001\n",
    "history_new = model.fit_generator(train_batches, samples_per_epoch=train_batches.nb_sample,\n",
    "                    validation_data=val_batches, nb_val_samples=val_batches.nb_sample,\n",
    "                    nb_epoch=5, verbose=True)\n",
    "history = update_history(history, history_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "27184/27184 [==============================] - 316s - loss: 4.2346 - acc: 0.1007 - val_loss: 3.9503 - val_acc: 0.1497\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-bc279f916fa3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_val_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_batches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnb_sample\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                     nb_epoch=1, verbose=True)\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "model.optimizer.lr=0.000001\n",
    "history_new = model.fit_generator(train_batches, samples_per_epoch=train_batches.nb_sample,\n",
    "                    validation_data=val_batches, nb_val_samples=val_batches.nb_sample,\n",
    "                    nb_epoch=1, verbose=True)\n",
    "history = update_history(history, history_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr=0.0000001\n",
    "history_new = model.fit_generator(train_batches, samples_per_epoch=train_batches.nb_sample,\n",
    "                    validation_data=val_batches, nb_val_samples=val_batches.nb_sample,\n",
    "                    nb_epoch=100, verbose=True)\n",
    "history = update_history(history, history_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "27184/27184 [==============================] - 168s - loss: 3.0107 - acc: 0.3190 - val_loss: 9.7742 - val_acc: 0.0853\n",
      "Epoch 2/30\n",
      "27184/27184 [==============================] - 171s - loss: 2.3195 - acc: 0.4146 - val_loss: 3.2141 - val_acc: 0.3220\n",
      "Epoch 3/30\n",
      "27184/27184 [==============================] - 178s - loss: 1.9687 - acc: 0.4579 - val_loss: 2.6561 - val_acc: 0.3791\n",
      "Epoch 4/30\n",
      "27184/27184 [==============================] - 169s - loss: 1.7481 - acc: 0.4985 - val_loss: 2.0476 - val_acc: 0.4213\n",
      "Epoch 5/30\n",
      "27184/27184 [==============================] - 162s - loss: 1.6184 - acc: 0.5283 - val_loss: 3.5724 - val_acc: 0.2582\n",
      "Epoch 6/30\n",
      "27184/27184 [==============================] - 161s - loss: 1.5127 - acc: 0.5539 - val_loss: 2.4700 - val_acc: 0.3731\n",
      "Epoch 7/30\n",
      "27184/27184 [==============================] - 162s - loss: 1.4419 - acc: 0.5693 - val_loss: 2.9279 - val_acc: 0.2947\n",
      "Epoch 8/30\n",
      "27184/27184 [==============================] - 162s - loss: 1.3834 - acc: 0.5777 - val_loss: 2.0762 - val_acc: 0.4603\n",
      "Epoch 9/30\n",
      "27184/27184 [==============================] - 167s - loss: 1.3573 - acc: 0.5895 - val_loss: 2.0528 - val_acc: 0.4565\n",
      "Epoch 10/30\n",
      "27184/27184 [==============================] - 162s - loss: 1.3205 - acc: 0.5953 - val_loss: 3.0329 - val_acc: 0.3017\n",
      "Epoch 11/30\n",
      "27184/27184 [==============================] - 161s - loss: 1.2734 - acc: 0.6049 - val_loss: 3.4152 - val_acc: 0.3560\n",
      "Epoch 12/30\n",
      "27184/27184 [==============================] - 161s - loss: 1.2447 - acc: 0.6166 - val_loss: 1.7265 - val_acc: 0.5178\n",
      "Epoch 13/30\n",
      "27184/27184 [==============================] - 166s - loss: 1.1989 - acc: 0.6257 - val_loss: 1.4931 - val_acc: 0.6053\n",
      "Epoch 14/30\n",
      "27184/27184 [==============================] - 169s - loss: 1.1761 - acc: 0.6305 - val_loss: 3.6419 - val_acc: 0.3182\n",
      "Epoch 15/30\n",
      "27184/27184 [==============================] - 178s - loss: 1.1698 - acc: 0.6327 - val_loss: 1.9799 - val_acc: 0.5038\n",
      "Epoch 16/30\n",
      "27184/27184 [==============================] - 186s - loss: 1.1200 - acc: 0.6432 - val_loss: 1.4495 - val_acc: 0.6079\n",
      "Epoch 17/30\n",
      "27184/27184 [==============================] - 187s - loss: 1.0635 - acc: 0.6567 - val_loss: 1.5350 - val_acc: 0.5949\n",
      "Epoch 18/30\n",
      "27184/27184 [==============================] - 186s - loss: 1.0423 - acc: 0.6642 - val_loss: 1.3896 - val_acc: 0.6215\n",
      "Epoch 19/30\n",
      "27184/27184 [==============================] - 186s - loss: 1.0349 - acc: 0.6624 - val_loss: 2.1821 - val_acc: 0.4886\n",
      "Epoch 20/30\n",
      "27184/27184 [==============================] - 186s - loss: 0.9983 - acc: 0.6723 - val_loss: 2.1046 - val_acc: 0.5181\n",
      "Epoch 21/30\n",
      "27184/27184 [==============================] - 187s - loss: 0.9908 - acc: 0.6759 - val_loss: 1.4824 - val_acc: 0.6171\n",
      "Epoch 22/30\n",
      "27184/27184 [==============================] - 188s - loss: 0.9556 - acc: 0.6866 - val_loss: 1.7217 - val_acc: 0.5470\n",
      "Epoch 23/30\n",
      "27184/27184 [==============================] - 186s - loss: 0.9622 - acc: 0.6854 - val_loss: 1.4488 - val_acc: 0.6326\n",
      "Epoch 24/30\n",
      "27184/27184 [==============================] - 186s - loss: 0.9265 - acc: 0.6936 - val_loss: 1.4554 - val_acc: 0.6313\n",
      "Epoch 25/30\n",
      "27184/27184 [==============================] - 186s - loss: 0.9050 - acc: 0.7028 - val_loss: 1.3996 - val_acc: 0.6136\n",
      "Epoch 26/30\n",
      "27184/27184 [==============================] - 186s - loss: 0.8707 - acc: 0.7095 - val_loss: 1.4890 - val_acc: 0.6196\n",
      "Epoch 27/30\n",
      "27184/27184 [==============================] - 185s - loss: 0.8665 - acc: 0.7084 - val_loss: 2.6342 - val_acc: 0.4569\n",
      "Epoch 28/30\n",
      "27184/27184 [==============================] - 186s - loss: 0.8522 - acc: 0.7131 - val_loss: 1.6207 - val_acc: 0.6110\n",
      "Epoch 29/30\n",
      "27184/27184 [==============================] - 186s - loss: 0.8227 - acc: 0.7216 - val_loss: 2.0933 - val_acc: 0.5615\n",
      "Epoch 30/30\n",
      "27184/27184 [==============================] - 187s - loss: 0.8009 - acc: 0.7274 - val_loss: 1.4950 - val_acc: 0.6431\n"
     ]
    }
   ],
   "source": [
    "# history = model.fit_generator(train_batches, samples_per_epoch=train_batches.nb_sample,\n",
    "#                     validation_data=val_batches, nb_val_samples=val_batches.nb_sample,\n",
    "#                     nb_epoch=30, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.save_weights('last_attempt_batch_norm.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Visualize Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7fcf099f2e10>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVwAAAFcCAYAAACEFgYsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nELgAYMj/A/VJL5Bk/DO0AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fcf099f2e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame(history.history)\n",
    "df['epoch_number'] = range(len(df))\n",
    "sns.lmplot(x=\"epoch_number\", y=\"val_acc\", data=df, fit_reg=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation + Batch Normalization + Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "img_rows, img_cols = 128, 128\n",
    "in_shape = (img_rows, img_cols)\n",
    "batch_size = 64\n",
    "nb_classes = 121\n",
    "mean_px = 0.046544086\n",
    "std_px = 0.15035126"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "heading_collapsed": true
   },
   "source": [
    "#### Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "batch_gen = image.ImageDataGenerator(\n",
    "                rotation_range=360,\n",
    "                width_shift_range=0.03,\n",
    "                height_shift_range=0.03,\n",
    "                shear_range=0.10,\n",
    "                zoom_range=0.10,\n",
    "                rescale=1. / 255,\n",
    "                horizontal_flip = True,\n",
    "                vertical_flip = True)\n",
    "\n",
    "valid_gen = image.ImageDataGenerator(\n",
    "#                                      featurewise_center=True,\n",
    "#                                      featurewise_std_normalization=True,\n",
    "                                     rescale=1. / 255\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 27184 images belonging to 121 classes.\n",
      "Found 3152 images belonging to 121 classes.\n"
     ]
    }
   ],
   "source": [
    "train_batches = get_batches(train_path, batch_size=batch_size, \n",
    "                            target_size=in_shape, color_mode=\"grayscale\", \n",
    "                            gen=batch_gen)\n",
    "val_batches   = get_batches(valid_path, batch_size=batch_size, \n",
    "                            target_size=in_shape, color_mode=\"grayscale\", \n",
    "                            gen=valid_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def norm_input(x): return (x-mean_px)/(std_px)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = Sequential([\n",
    "        Lambda(norm_input, input_shape=(1, img_rows, img_cols), output_shape=(1, img_rows, img_cols)),\n",
    "        Convolution2D(64,3,3, border_mode='same', activation='relu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        Convolution2D(64,3,3, border_mode='same', activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        BatchNormalization(axis=1),\n",
    "        Convolution2D(128,3,3, border_mode='same', activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        BatchNormalization(axis=1),\n",
    "        Convolution2D(256,3,3, border_mode='same', activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        Flatten(),\n",
    "        BatchNormalization(),\n",
    "        Dense(2048, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.2),\n",
    "        Dense(2048, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        Dense(2048, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.4),\n",
    "        Dense(nb_classes, activation='softmax')\n",
    "        ])\n",
    "    model.compile(Adam(decay=0.01), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nathan/anaconda3/envs/deepLearning/lib/python3.5/site-packages/keras/layers/core.py:622: UserWarning: `output_shape` argument not specified for layer lambda_1 and cannot be automatically inferred with the Theano backend. Defaulting to output shape `(None, 1, 128, 128)` (same as input shape). If the expected output shape is different, specify it via the `output_shape` argument.\n",
      "  .format(self.name, input_shape))\n"
     ]
    }
   ],
   "source": [
    "model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lambda_1 (Lambda)                (None, 1, 128, 128)   0           lambda_input_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_1 (Convolution2D)  (None, 64, 128, 128)  640         lambda_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_1 (BatchNorma (None, 64, 128, 128)  256         convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 64, 128, 128)  36928       batchnormalization_1[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_1 (MaxPooling2D)    (None, 64, 64, 64)    0           convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_2 (BatchNorma (None, 64, 64, 64)    256         maxpooling2d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)  (None, 128, 64, 64)   73856       batchnormalization_2[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_2 (MaxPooling2D)    (None, 128, 32, 32)   0           convolution2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_3 (BatchNorma (None, 128, 32, 32)   512         maxpooling2d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_4 (Convolution2D)  (None, 256, 32, 32)   295168      batchnormalization_3[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_3 (MaxPooling2D)    (None, 256, 16, 16)   0           convolution2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 65536)         0           maxpooling2d_3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_4 (BatchNorma (None, 65536)         262144      flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 2048)          134219776   batchnormalization_4[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_5 (BatchNorma (None, 2048)          8192        dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 2048)          0           batchnormalization_5[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 2048)          4196352     dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_6 (BatchNorma (None, 2048)          8192        dense_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 2048)          0           batchnormalization_6[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 2048)          4196352     dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_7 (BatchNorma (None, 2048)          8192        dense_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 2048)          0           batchnormalization_7[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 121)           247929      dropout_3[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 143,554,745\n",
      "Trainable params: 143,410,873\n",
      "Non-trainable params: 143,872\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_history(old, new):\n",
    "    for key, value in new.history.items():\n",
    "        old.history[key] = (old.history[key] + value)\n",
    "    return old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "27184/27184 [==============================] - 166s - loss: 3.2261 - acc: 0.2921 - val_loss: 10.9946 - val_acc: 0.0774\n",
      "Epoch 2/30\n",
      "27184/27184 [==============================] - 162s - loss: 2.5152 - acc: 0.3885 - val_loss: 2.7048 - val_acc: 0.3334\n",
      "Epoch 3/30\n",
      "27184/27184 [==============================] - 161s - loss: 2.2480 - acc: 0.4311 - val_loss: 2.9879 - val_acc: 0.3096\n",
      "Epoch 4/30\n",
      "27184/27184 [==============================] - 162s - loss: 2.0946 - acc: 0.4570 - val_loss: 3.5947 - val_acc: 0.1846\n",
      "Epoch 5/30\n",
      "27184/27184 [==============================] - 162s - loss: 1.9956 - acc: 0.4674 - val_loss: 4.2786 - val_acc: 0.2116\n",
      "Epoch 6/30\n",
      "27184/27184 [==============================] - 162s - loss: 1.9011 - acc: 0.4946 - val_loss: 2.7187 - val_acc: 0.3293\n",
      "Epoch 7/30\n",
      "27184/27184 [==============================] - 165s - loss: 1.7281 - acc: 0.5108 - val_loss: 2.6375 - val_acc: 0.4026\n",
      "Epoch 8/30\n",
      "27184/27184 [==============================] - 167s - loss: 1.6054 - acc: 0.5356 - val_loss: 1.6365 - val_acc: 0.5479\n",
      "Epoch 9/30\n",
      "27184/27184 [==============================] - 169s - loss: 1.6049 - acc: 0.5341 - val_loss: 1.5212 - val_acc: 0.5514\n",
      "Epoch 10/30\n",
      "27184/27184 [==============================] - 165s - loss: 1.4954 - acc: 0.5533 - val_loss: 6.1532 - val_acc: 0.3268\n",
      "Epoch 11/30\n",
      "27184/27184 [==============================] - 163s - loss: 1.4536 - acc: 0.5665 - val_loss: 9.0973 - val_acc: 0.1808\n",
      "Epoch 12/30\n",
      "27184/27184 [==============================] - 163s - loss: 1.5090 - acc: 0.5599 - val_loss: 4.8861 - val_acc: 0.0936\n",
      "Epoch 13/30\n",
      "27184/27184 [==============================] - 164s - loss: 1.4613 - acc: 0.5642 - val_loss: 1.6821 - val_acc: 0.5473\n",
      "Epoch 14/30\n",
      "27184/27184 [==============================] - 169s - loss: 1.3722 - acc: 0.5874 - val_loss: 1.5137 - val_acc: 0.5730\n",
      "Epoch 15/30\n",
      "27184/27184 [==============================] - 167s - loss: 1.3570 - acc: 0.5902 - val_loss: 3.1917 - val_acc: 0.3306\n",
      "Epoch 16/30\n",
      "27184/27184 [==============================] - 166s - loss: 1.3321 - acc: 0.5982 - val_loss: 1.9725 - val_acc: 0.5051\n",
      "Epoch 17/30\n",
      "27184/27184 [==============================] - 164s - loss: 1.2658 - acc: 0.6146 - val_loss: 1.3961 - val_acc: 0.6022\n",
      "Epoch 18/30\n",
      "27184/27184 [==============================] - 165s - loss: 1.2621 - acc: 0.6138 - val_loss: 1.6786 - val_acc: 0.5520\n",
      "Epoch 19/30\n",
      "27184/27184 [==============================] - 166s - loss: 1.2451 - acc: 0.6166 - val_loss: 1.4650 - val_acc: 0.6063\n",
      "Epoch 20/30\n",
      "27184/27184 [==============================] - 166s - loss: 1.2118 - acc: 0.6266 - val_loss: 1.3380 - val_acc: 0.6212\n",
      "Epoch 21/30\n",
      "27184/27184 [==============================] - 164s - loss: 1.2039 - acc: 0.6256 - val_loss: 1.6373 - val_acc: 0.5558\n",
      "Epoch 22/30\n",
      "27184/27184 [==============================] - 167s - loss: 1.1852 - acc: 0.6307 - val_loss: 1.9484 - val_acc: 0.5070\n",
      "Epoch 23/30\n",
      "27184/27184 [==============================] - 167s - loss: 1.1590 - acc: 0.6386 - val_loss: 1.3941 - val_acc: 0.6129\n",
      "Epoch 24/30\n",
      "27184/27184 [==============================] - 168s - loss: 1.1505 - acc: 0.6416 - val_loss: 1.2978 - val_acc: 0.6405\n",
      "Epoch 25/30\n",
      "27184/27184 [==============================] - 166s - loss: 1.1386 - acc: 0.6407 - val_loss: 1.8161 - val_acc: 0.5365\n",
      "Epoch 26/30\n",
      "27184/27184 [==============================] - 167s - loss: 1.1259 - acc: 0.6476 - val_loss: 4.8236 - val_acc: 0.2573\n",
      "Epoch 27/30\n",
      "27184/27184 [==============================] - 168s - loss: 1.1228 - acc: 0.6468 - val_loss: 1.4669 - val_acc: 0.6348\n",
      "Epoch 28/30\n",
      "27184/27184 [==============================] - 169s - loss: 1.0979 - acc: 0.6568 - val_loss: 1.4196 - val_acc: 0.6342\n",
      "Epoch 29/30\n",
      "27184/27184 [==============================] - 169s - loss: 1.0829 - acc: 0.6576 - val_loss: 1.3979 - val_acc: 0.6177\n",
      "Epoch 30/30\n",
      "27184/27184 [==============================] - 168s - loss: 1.0897 - acc: 0.6556 - val_loss: 6.0673 - val_acc: 0.2072\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(train_batches, samples_per_epoch=train_batches.nb_sample,\n",
    "                    validation_data=val_batches, nb_val_samples=val_batches.nb_sample,\n",
    "                    nb_epoch=300, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights('last_attempt_dropout.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "27184/27184 [==============================] - 168s - loss: 1.0591 - acc: 0.6651 - val_loss: 2.6359 - val_acc: 0.4648\n",
      "Epoch 2/5\n",
      "27184/27184 [==============================] - 165s - loss: 1.0710 - acc: 0.6661 - val_loss: 7.6091 - val_acc: 0.1742\n",
      "Epoch 3/5\n",
      "27184/27184 [==============================] - 162s - loss: 1.0390 - acc: 0.6671 - val_loss: 1.4861 - val_acc: 0.6269\n",
      "Epoch 4/5\n",
      "27184/27184 [==============================] - 163s - loss: 1.0293 - acc: 0.6702 - val_loss: 1.4595 - val_acc: 0.6310\n",
      "Epoch 5/5\n",
      "27184/27184 [==============================] - 161s - loss: 1.0618 - acc: 0.6632 - val_loss: 3.1094 - val_acc: 0.4201\n"
     ]
    }
   ],
   "source": [
    "model.optimizer.lr=0.001\n",
    "history_new = model.fit_generator(train_batches, samples_per_epoch=train_batches.nb_sample,\n",
    "                    validation_data=val_batches, nb_val_samples=val_batches.nb_sample,\n",
    "                    nb_epoch=5, verbose=True)\n",
    "history = update_history(history, history_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "27184/27184 [==============================] - 162s - loss: 1.0368 - acc: 0.6707 - val_loss: 1.3661 - val_acc: 0.6301\n",
      "Epoch 2/5\n",
      "27184/27184 [==============================] - 162s - loss: 1.0116 - acc: 0.6753 - val_loss: 1.4064 - val_acc: 0.6666\n",
      "Epoch 3/5\n",
      " 8256/27184 [========>.....................] - ETA: 110s - loss: 0.9586 - acc: 0.6846"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-8a8be00220ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m history_new = model.fit_generator(train_batches, samples_per_epoch=train_batches.nb_sample,\n\u001b[1;32m      3\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_val_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_batches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnb_sample\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                     nb_epoch=5, verbose=True)\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nathan/anaconda3/envs/deepLearning/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    933\u001b[0m                                         \u001b[0mnb_worker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_worker\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m                                         \u001b[0mpickle_safe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle_safe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 935\u001b[0;31m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    936\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m     def evaluate_generator(self, generator, val_samples,\n",
      "\u001b[0;32m/home/nathan/anaconda3/envs/deepLearning/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe, initial_epoch)\u001b[0m\n\u001b[1;32m   1555\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   1556\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1557\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1559\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nathan/anaconda3/envs/deepLearning/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1318\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1320\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1321\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nathan/anaconda3/envs/deepLearning/lib/python3.5/site-packages/keras/backend/theano_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    957\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 959\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    960\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nathan/anaconda3/envs/deepLearning/lib/python3.5/site-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    857\u001b[0m                                 self.input_storage[i].storage[0])\n\u001b[1;32m    858\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m         \u001b[0;31m# Check if inputs are missing, or if inputs were set more than once, or\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m         \u001b[0;31m# if we tried to provide inputs that are supposed to be implicit.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrust_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nathan/anaconda3/envs/deepLearning/lib/python3.5/site-packages/theano/ifelse.py\u001b[0m in \u001b[0;36mthunk\u001b[0;34m()\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0mcondition_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcondition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloatX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         return ([condition_grad] +\n\u001b[0;32m--> 237\u001b[0;31m                 \u001b[0mif_true_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mif_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreturn_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m                 if_false_op(*if_false, **dict(return_list=True)))\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.optimizer.lr=0.0001\n",
    "history_new = model.fit_generator(train_batches, samples_per_epoch=train_batches.nb_sample,\n",
    "                    validation_data=val_batches, nb_val_samples=val_batches.nb_sample,\n",
    "                    nb_epoch=5, verbose=True)\n",
    "history = update_history(history, history_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr=0.00001\n",
    "history_new = model.fit_generator(train_batches, samples_per_epoch=train_batches.nb_sample,\n",
    "                    validation_data=val_batches, nb_val_samples=val_batches.nb_sample,\n",
    "                    nb_epoch=5, verbose=True)\n",
    "history = update_history(history, history_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr=0.000001\n",
    "history_new = model.fit_generator(train_batches, samples_per_epoch=train_batches.nb_sample,\n",
    "                    validation_data=val_batches, nb_val_samples=val_batches.nb_sample,\n",
    "                    nb_epoch=5, verbose=True)\n",
    "history = update_history(history, history_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr=0.0000001\n",
    "history_new = model.fit_generator(train_batches, samples_per_epoch=train_batches.nb_sample,\n",
    "                    validation_data=val_batches, nb_val_samples=val_batches.nb_sample,\n",
    "                    nb_epoch=5, verbose=True)\n",
    "history = update_history(history, history_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Visualize Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(history.history)\n",
    "df['epoch_number'] = range(len(df))\n",
    "sns.lmplot(x=\"epoch_number\", y=\"val_acc\", data=df, fit_reg=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Try out different learning rates below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "So far it looks like the validation accuracy is jumping around like crazy while the training accuracy keeps going up. This can be from two possible reasons:\n",
    "*  Learning rate is too high\n",
    "*  Need dropout (overfitting really hard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# model.save_weights('keep_lowering_learning_rate.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('keep_lowering_learning_rate.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "27184/27184 [==============================] - 184s - loss: 0.5837 - acc: 0.7977 - val_loss: 1.3196 - val_acc: 0.6878\n",
      "Epoch 2/3\n",
      "27184/27184 [==============================] - 185s - loss: 0.5793 - acc: 0.8005 - val_loss: 1.3142 - val_acc: 0.6859\n",
      "Epoch 3/3\n",
      "27184/27184 [==============================] - 186s - loss: 0.5706 - acc: 0.8005 - val_loss: 1.3022 - val_acc: 0.6938\n"
     ]
    }
   ],
   "source": [
    "model.optimizer.lr=0.000001\n",
    "history2 = model.fit_generator(train_batches, samples_per_epoch=train_batches.nb_sample,\n",
    "                    validation_data=val_batches, nb_val_samples=val_batches.nb_sample,\n",
    "                    nb_epoch=3, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7f4cb11e57b8>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAAFgCAYAAACFYaNMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nqRALWJIKsYAlqRALWJIKsYAlqZD/D8WccC6GTa0ZAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4cb11e5828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame(history.history)\n",
    "df['epoch_number'] = range(len(df))\n",
    "sns.lmplot(x=\"epoch_number\", y=\"val_acc\", data=df, fit_reg=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Ensembling "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:deepLearning]",
   "language": "python",
   "name": "conda-env-deepLearning-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
