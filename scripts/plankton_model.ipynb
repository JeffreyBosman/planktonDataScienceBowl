{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# National Data Science Bowl - Plankton\n",
    "\n",
    "## Action Plan\n",
    "\n",
    "* Make overfitting model\n",
    "* Data augmentation\n",
    "* Batch normalization\n",
    "* Dropout\n",
    "* Ensembling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Imports and Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Create references to important directories we will use over and over\n",
    "import os, sys\n",
    "current_dir = os.getcwd()\n",
    "SCRIPTS_HOME_DIR = current_dir\n",
    "DATA_HOME_DIR = current_dir+'/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX 1070 (CNMeM is enabled with initial size: 90.0% of memory, cuDNN 5105)\n",
      "/home/nathan/anaconda3/envs/deepLearning/lib/python3.5/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "#import modules\n",
    "from utils import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/nathan/git/planktonDataScienceBowl/scripts/data\n"
     ]
    }
   ],
   "source": [
    "%cd $DATA_HOME_DIR\n",
    "\n",
    "#Set path to sample/ path if desired\n",
    "path = DATA_HOME_DIR #'/sample/'\n",
    "test_path = DATA_HOME_DIR + '/test/' #We use all the test data\n",
    "results_path=DATA_HOME_DIR + '/results/'\n",
    "train_path=path + '/train/'\n",
    "valid_path=path + '/valid/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## VGG Like Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "img_rows, img_cols = 128, 128\n",
    "in_shape = (img_rows, img_cols)\n",
    "batch_size = 64\n",
    "nb_classes = 121"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "gen = image.ImageDataGenerator(rescale=1. / 255)\n",
    "# gen = image.ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 27184 images belonging to 121 classes.\n",
      "Found 3152 images belonging to 121 classes.\n"
     ]
    }
   ],
   "source": [
    "train_batches = get_batches(train_path, batch_size=batch_size, \n",
    "                            target_size=in_shape, color_mode=\"grayscale\", \n",
    "                            gen=gen)\n",
    "val_batches   = get_batches(valid_path, batch_size=batch_size, \n",
    "                            target_size=in_shape, color_mode=\"grayscale\", \n",
    "                            gen=gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = Sequential([\n",
    "        Convolution2D(64,3,3, border_mode='same', activation='relu', input_shape=(1, img_rows, img_cols)),\n",
    "        Convolution2D(64,3,3, border_mode='same', activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        Convolution2D(128,3,3, border_mode='same', activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        Convolution2D(256,3,3, border_mode='same', activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        Flatten(),\n",
    "        Dense(2048, activation='relu'),\n",
    "        Dense(2048, activation='relu'),\n",
    "        Dense(2048, activation='relu'),\n",
    "        Dense(nb_classes, activation='softmax')\n",
    "        ])\n",
    "    model.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_1 (Convolution2D)  (None, 64, 128, 128)  640         convolution2d_input_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 64, 128, 128)  36928       convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_1 (MaxPooling2D)    (None, 64, 64, 64)    0           convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)  (None, 128, 64, 64)   73856       maxpooling2d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_2 (MaxPooling2D)    (None, 128, 32, 32)   0           convolution2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_4 (Convolution2D)  (None, 256, 32, 32)   295168      maxpooling2d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_3 (MaxPooling2D)    (None, 256, 16, 16)   0           convolution2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 65536)         0           maxpooling2d_3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 2048)          134219776   flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 2048)          4196352     dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 2048)          4196352     dense_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 121)           247929      dense_3[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 143,267,001\n",
      "Trainable params: 143,267,001\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "27184/27184 [==============================] - 115s - loss: 2.5802 - acc: 0.3409 - val_loss: 1.9055 - val_acc: 0.4753\n",
      "Epoch 2/5\n",
      "11520/27184 [===========>..................] - ETA: 64s - loss: 1.7021 - acc: 0.5028"
     ]
    }
   ],
   "source": [
    "model.fit_generator(train_batches, samples_per_epoch=train_batches.nb_sample,\n",
    "                    nb_epoch=5,\n",
    "                    validation_data=val_batches,\n",
    "                    nb_val_samples=val_batches.nb_sample,\n",
    "                    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr=0.1\n",
    "model.fit_generator(train_batches, samples_per_epoch=train_batches.nb_sample,\n",
    "                    nb_epoch=1,\n",
    "                    validation_data=val_batches, nb_val_samples=val_batches.nb_sample,\n",
    "                    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr=0.01\n",
    "model.fit_generator(train_batches, samples_per_epoch=train_batches.nb_sample,\n",
    "                    nb_epoch=4,\n",
    "                    validation_data=val_batches, nb_val_samples=val_batches.nb_sample,\n",
    "                    verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_rows, img_cols = 128, 128\n",
    "in_shape = (img_rows, img_cols)\n",
    "batch_size = 64\n",
    "nb_classes = 121"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_gen = image.ImageDataGenerator(\n",
    "                rotation_range=360,\n",
    "                width_shift_range=0.03,\n",
    "                height_shift_range=0.03,\n",
    "                shear_range=0.10,\n",
    "                zoom_range=0.10,\n",
    "                rescale=1. / 255,\n",
    "                horizontal_flip = True,\n",
    "                vertical_flip = True)\n",
    "\n",
    "valid_gen = image.ImageDataGenerator(rescale=1. / 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 27184 images belonging to 121 classes.\n",
      "Found 3152 images belonging to 121 classes.\n"
     ]
    }
   ],
   "source": [
    "train_batches = get_batches(train_path, batch_size=batch_size, \n",
    "                            target_size=in_shape, color_mode=\"grayscale\", \n",
    "                            gen=batch_gen)\n",
    "val_batches   = get_batches(valid_path, batch_size=batch_size, \n",
    "                            target_size=in_shape, color_mode=\"grayscale\", \n",
    "                            gen=valid_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = Sequential([\n",
    "        Convolution2D(64,3,3, border_mode='same', activation='relu', input_shape=(1, img_rows, img_cols)),\n",
    "        Convolution2D(64,3,3, border_mode='same', activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        Convolution2D(128,3,3, border_mode='same', activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        Convolution2D(256,3,3, border_mode='same', activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        Flatten(),\n",
    "        Dense(2048, activation='relu'),\n",
    "        Dense(2048, activation='relu'),\n",
    "        Dense(2048, activation='relu'),\n",
    "        Dense(nb_classes, activation='softmax')\n",
    "        ])\n",
    "    model.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_9 (Convolution2D)  (None, 64, 128, 128)  640         convolution2d_input_3[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_10 (Convolution2D) (None, 64, 128, 128)  36928       convolution2d_9[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_7 (MaxPooling2D)    (None, 64, 64, 64)    0           convolution2d_10[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_11 (Convolution2D) (None, 128, 64, 64)   73856       maxpooling2d_7[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_8 (MaxPooling2D)    (None, 128, 32, 32)   0           convolution2d_11[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_12 (Convolution2D) (None, 256, 32, 32)   295168      maxpooling2d_8[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_9 (MaxPooling2D)    (None, 256, 16, 16)   0           convolution2d_12[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)              (None, 65536)         0           maxpooling2d_9[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_9 (Dense)                  (None, 2048)          134219776   flatten_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_10 (Dense)                 (None, 2048)          4196352     dense_9[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_11 (Dense)                 (None, 2048)          4196352     dense_10[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_12 (Dense)                 (None, 121)           247929      dense_11[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 143,267,001\n",
      "Trainable params: 143,267,001\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "24832/27184 [==========================>...] - ETA: 9s - loss: 3.1592 - acc: 0.2349"
     ]
    }
   ],
   "source": [
    "model.fit_generator(train_batches, samples_per_epoch=train_batches.nb_sample,\n",
    "                    validation_data=val_batches, nb_val_samples=val_batches.nb_sample,\n",
    "                    nb_epoch=25, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr=0.1\n",
    "model.fit_generator(train_batches, samples_per_epoch=train_batches.nb_sample,\n",
    "                    nb_epoch=1,\n",
    "                    validation_data=val_batches, nb_val_samples=val_batches.nb_sample,\n",
    "                    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr=0.01\n",
    "model.fit_generator(train_batches, samples_per_epoch=train_batches.nb_sample,\n",
    "                    nb_epoch=4,\n",
    "                    validation_data=val_batches, nb_val_samples=val_batches.nb_sample,\n",
    "                    verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# image_generator = image.ImageDataGenerator(\n",
    "#                 rotation_range=360,\n",
    "#                 width_shift_range=0.02,\n",
    "#                 height_shift_range=0.02,\n",
    "#                 shear_range=0.05,\n",
    "#                 zoom_range=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Batch Normalization "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Dropout "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Ensembling "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:deepLearning]",
   "language": "python",
   "name": "conda-env-deepLearning-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
